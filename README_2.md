# Отчёт по итерации «Отработка модели»

## Введение

Вторая итерация была посвящена улучшению качества распознавания русскоязычных бухгалтерских документов путём расширения и «ужесточения» пост-обработки результатов OCR.
Основной задачей было повысить читаемость итогового текста и минимизировать характерные для OCR ошибки: смешение кириллицы и латиницы, искажения числовых токенов, «каша» в доменных терминах и нестабильные фрагменты текста.

В рамках итерации также была предпринята попытка интегрировать локальные LLM-модели для дополнительной интеллектуальной коррекции текста — однако результаты оказались нестабильными, а затраты ресурсов слишком высокими.

## Ход работы

### 1. Улучшение пост-обработки PaddleOCR

С учётом опыта первой итерации была существенно расширена и усложнена система нормализации текста.
Основные направления доработки:

#### 1.1. Сужение алфавита

Был сформирован минимальный допустимый алфавит из:

* кириллицы,
* базовой пунктуации,
* символов валют,
* спец-знаков («№», «%», «/», «#» и др.).

Это позволило сократить количество классов и уменьшить вероятность путаницы между похожими символами.

#### 1.2. Унификация юникода: NFKC

Все строки проходят нормализацию NFKC — это устраняет разнобой в написании букв, символов валюты, пробелов и составных символов.

#### 1.3. Преобразование латиницы в визуально схожую кириллицу

Реализована таблица `HOMOGRAPH_MAP`, устраняющая типичные OCR-ошибки:

* A → А
* B → В
* H → Н
* P → Р
* X → Х
  и др.

Это снизило количество ложных слов, состоящих из визуально похожей латиницы.

#### 1.4. Числовые поля: детекция и нормализация

Цифроподобные буквы внутри чисел теперь заменяются автоматически:

* O/О → 0
* З → 3
* б/Б → 6
* I/l → 1

Далее выполняется:

* очистка мусорных хвостов,
* нормализация запятых/точек,
* устранение пробелов внутри чисел,
* выравнивание ведущих нулей.

#### 1.5. Канонизация ключевых терминов

По ранее установленным регулярным шаблонам (см. `TERMS_CANON`) приводятся к единому виду:

* Продавец
* Покупатель
* Счёт-фактура
* Единица
* Ставка НДС
* Всего к оплате
  и т.д.

Это критично для документов 1С, где терминология фиксирована.

#### 1.6. Словарь характерных OCR-ошибок

Реализован ручной словарь исправления типичных искажений:

* Стоимосt → стоимость
* финансв → финансов
* убьтки → убытки
  и др.

#### 1.7. Лексикон + Левенштейн

Для слов длиной 4+ выполняется «мягкая» корректировка по доменному словарю `DOMAIN_WORDS`, если расстояние Левенштейна ≤ 2.
Это помогает править варианты вроде:

* «стоимостb»
* «актиbы»
* «кредитне»

и возвращать их в каноническую форму.

### 2. Результаты по метрикам

Для оценки влияния пост-обработки использовались сравнения результата OCR до и после нормализации.
Важно подчеркнуть:

### ❗ CER/WER в этой итерации **не являются показателями качества итогового текста**, а показывают **насколько сильно финальный текст отличается от сырого OCR**.

Поскольку пост-обработка стала агрессивной и активно исправляет текст, ожидаемо **CER/WER растут**, что отражает глубину изменений.

#### Метрики:

| Этап                                     | CER    | WER    | Примечание                                        |
| ---------------------------------------- | ------ | ------ | ------------------------------------------------- |
| Базовый OCR + минимальная пост-обработка | 0.0722 | 0.2084 | Текст близок к сирому OCR                         |
| Улучшенная пост-обработка                | 0.1842 | 0.5467 | Результат значительно отличается от исходного OCR |
| Улучшенная пост-обработка + 400 dpi      | 0.1704 | 0.5440 | DPI сглаживает отдельные ошибки, эффект умеренный |

Рост метрик в данном случае — ожидаемое следствие активной нормализации текста, а не ухудшение качества системы.
При визуальной проверке коэффициент «каши» действительно снижается, но **ошибок всё ещё довольно много**, что подтверждает необходимость дальнейших улучшений.

### 3. Попытка интеграции локальных LLM

#### 3.1. Использованные модели

* **gpt4all-falcon-newbpe-q4_0.gguf**
* **Qwen2-1.5B-Instruct**

Сценарий работы:

```
OCR → пост-обработка → LLM → финальный текст
```

#### 3.2. Ожидаемый эффект

Планировалось, что LLM:

* исправит грубые OCR-искажения, неразличимые правилами,
* доведёт «кашу» до читаемого вида,
* стабилизирует формат терминов и чисел.

Примеры задач:

* «Cm0иМосtь» → «Стоимость»
* «АКТиbы» → «Активы»

#### 3.3. Реальные результаты

LLM-модели:

* **не соблюдали строгие промты**,
* **генерировали лишний текст**,
* **пропускали задания**,
* **игнорировали доменные ограничения**,
* иногда «фантазировали» на пустом месте.

Для систем документооборота подобная нестабильность недопустима — требуются воспроизводимые результаты.

#### 3.4. Ограничения по железу

Тестирование проводилось:

* **8 ГБ RAM**, CPU-режим.
* Qwen-2 1.5B потребляла около **3 ГБ оперативы** и загружала CPU на ~30%.

Такие требования могут оказаться чрезмерными для инфраструктуры заказчика — на «картофельных» серверах подобные модели запускаться не будут.

**Вывод:**
Интеграция LLM на данной стадии признана нецелесообразной: влияние на качество невелико, а инженерные затраты и ограничения по железу — значительные.

## Итоги и выводы

1. Пост-обработка существенно усложнилась и теперь включает разностороннюю нормализацию, исправление OCR-типовых ошибок, работу с числами и доменными терминами.
2. CER/WER ожидаемо выросли, отражая активность преобразования текста, но не давая оценки качества.
3. При визуальной оценке текст стал заметно лучше — меньше «каши», меньше ошибок смешения алфавита, аккуратнее цифры.
4. Полностью решённой проблему считать нельзя: ошибки OCR всё ещё встречаются часто.
5. Попытка интеграции локальной LLM показала низкую предсказуемость результатов и неподъёмные требования к ресурсам.
6. Принято решение временно отказаться от LLM-пост-коррекции и сфокусироваться на улучшении:
   – OCR-модели,
   – доменного словаря,
   – регулярных паттернов и числовых валидаторов.

## Обновленный пайплайн

    A[Вход: скан/фото (до 400 dpi)] --> B[Предобработка\n(deskew, контраст, нормализация dpi)]
    B --> C[Детекция текстовых областей\n(DB / PP-OCRv3-det)]
    C --> D[Рекогнайзер текста\n(PaddleOCR, fine-tuned кириллица)]
    D --> E[Пост-обработка строк\n(NFKC, латиница→кириллица,\nсловари ошибок, числа, лексикон)]
    E --> F[Валидация ключевых реквизитов\n(ИНН, КПП, ОГРН, даты, суммы, валюты)]
    F --> G[Экспорт результатов\n(JSON / CSV)]

    %% Отключённая экспериментальная ветка:
    E -. эксперимент .-> L[LLM-посткоррекция\n(gpt4all / Qwen2-1.5B)]
    L -. отключено из-за\nнепредсказуемости и ресурсов .- F

## Распределение по задачам см на доске канбас на гитахбе проекта

**От лица тимлида (по данным доски Canvas):**

### **1. Анкудинов Олег Андреевич**

* Улучшение пост-обработки PaddleOCR
* Мягкая корректировка по Левенштейну
* Попытка интеграции локальных LLM

### **2. Архипов Роман Павлович**

* Канонизация ключевых терминов
* Словарь характерных OCR-ошибок
* Расчёт метрик

### **3. Зайченко Иван Андреевич**

* Сужение допустимых элементов и унификация юникода
* Преобразование латиницы в кириллицу и нормализация числовых полей
* Попытка интеграции локальных LLM (анализ результатов)

### **4. Кобелев Данила Александрович**

* Словарь характерных OCR-ошибок (расширение и пополнение)
* Преобразование латиницы в кириллицу (тестирование и отладка)
* Расчёт метрик (валидация)

### **5. Соболев Александр Андреевич**

* Разработка и интеграция полного пайплайна пост-обработки
* Анализ ошибок OCR и подготовка итоговой отчётности
* Поддержка модулей нормализации числовых и текстовых полей

### **3. Беззубин Сергей Алексеевич**

   * Улучшение пост-обработки PaddleOCR
   * Сужение допустимых элементов и унификация юникода
   * Словарь характерных OCR ошибок
   * Мягкая корректировка по Левенштейну
   * Расчет метрик
   * Попытка интеграции локальных LLM